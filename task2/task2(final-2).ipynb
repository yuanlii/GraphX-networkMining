{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Attribute Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describtion: For attribute prediction, I construct the graph using similar method as what I did in task 1. But instead of randomly selected nodes from network file, I chose the nodes particularly from test data first to construct the network, because I think that's what we actually care about and ultimately want to get the results. However, simply using test node is not enough, since we would want our test node to be around the training nodes, so that we can predict the test node attributes based on training nodes' attributes. So I add the training nodes when they are either in the test-node subgraph or in its neighborhood. Then I get a list of neighboring nodes and use the \"majority vote\" intuition to decide which attributes should the target test node adopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id1</th>\n",
       "      <th>node_id2</th>\n",
       "      <th>edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3942361</td>\n",
       "      <td>4009630</td>\n",
       "      <td>(3942361, 4009630)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1862789</td>\n",
       "      <td>2403557</td>\n",
       "      <td>(1862789, 2403557)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3559086</td>\n",
       "      <td>3449838</td>\n",
       "      <td>(3559086, 3449838)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4268588</td>\n",
       "      <td>6041523</td>\n",
       "      <td>(4268588, 6041523)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3067063</td>\n",
       "      <td>3845402</td>\n",
       "      <td>(3067063, 3845402)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id1  node_id2               edges\n",
       "0   3942361   4009630  (3942361, 4009630)\n",
       "1   1862789   2403557  (1862789, 2403557)\n",
       "2   3559086   3449838  (3559086, 3449838)\n",
       "3   4268588   6041523  (4268588, 6041523)\n",
       "4   3067063   3845402  (3067063, 3845402)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = pd.read_csv('network.tsv',sep = '\\t',header=None)\n",
    "network = network.rename(columns={0: 'node_id1', 1: 'node_id2'})\n",
    "network['edges'] = list(zip(network['node_id1'], network['node_id2']))\n",
    "network.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5509623</td>\n",
       "      <td>T0:0 T1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6334893</td>\n",
       "      <td>T0:0 T1:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218900</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3871398</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3942361</td>\n",
       "      <td>T0:0 T1:3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id attributes\n",
       "0  5509623  T0:0 T1:0\n",
       "1  6334893  T0:0 T1:1\n",
       "2  1218900  T0:1 T1:2\n",
       "3  3871398  T0:1 T1:2\n",
       "4  3942361  T0:0 T1:3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import training data - 5301403 records\n",
    "train = pd.read_csv('data/labeled-vertices.train.tsv', sep = '\\t', header = None)\n",
    "train = train.rename(columns={0: 'node_id', 1: 'attributes'})\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4546232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6394112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5883774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2843733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id\n",
       "0  4546232\n",
       "1  3711008\n",
       "2  6394112\n",
       "3  5883774\n",
       "4  2843733"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import test data (662675 rows; type:float64)\n",
    "test = pd.read_csv('data/unlabeled-vertices.test.txt',header = None)\n",
    "test = test.rename(columns={0: 'node_id'})\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30812820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nodes = train.node_id.tolist()\n",
    "\n",
    "include_train_df = network[(network.node_id1.isin(train_nodes) == True) | (network.node_id2.isin(train_nodes) == True)]\n",
    "include_train_df.head()  \n",
    "len(include_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add nearby train nodes upon include_test_df\n",
    "test_nodes = test.node_id.tolist()\n",
    "subset_df = include_train_df[(include_train_df.node_id1.isin(test_nodes) == True) | (include_train_df.node_id2.isin(test_nodes) == True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct graph\n",
    "subset_edge_list = subset_df['edges'].tolist()\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(subset_edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156688"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in_graph = train[train.node_id.isin(G.nodes()) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse attributes to training data nodes (in random graph)\n",
    "\n",
    "attr_dict = {}\n",
    "# for (k,v) in zip(train.node_id,train.attributes):\n",
    "for (k,v) in zip(train_in_graph.node_id,train_in_graph.attributes):\n",
    "    node_attrs = {}\n",
    "    attrs = v.split() # ['T0:0', 'T1:0']\n",
    "    \n",
    "    node_attrs = {}        \n",
    "    for attr in attrs:\n",
    "        key = attr.split(':')[0] # key\n",
    "        value = attr.split(':')[1] # value\n",
    "        node_attrs[key] = value\n",
    "    \n",
    "    attr_dict[k] = node_attrs\n",
    "\n",
    "nx.set_node_attributes(G, attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5509623</td>\n",
       "      <td>T0:0 T1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6334893</td>\n",
       "      <td>T0:0 T1:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218900</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3871398</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3942361</td>\n",
       "      <td>T0:0 T1:3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4009630</td>\n",
       "      <td>T0:0 T1:4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3890082</td>\n",
       "      <td>T0:0 T1:5 T8:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1010073</td>\n",
       "      <td>T0:0 T1:6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3348867</td>\n",
       "      <td>T0:0 T1:7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4017062</td>\n",
       "      <td>T0:0 T1:8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id      attributes\n",
       "0  5509623       T0:0 T1:0\n",
       "1  6334893       T0:0 T1:1\n",
       "2  1218900       T0:1 T1:2\n",
       "3  3871398       T0:1 T1:2\n",
       "4  3942361       T0:0 T1:3\n",
       "5  4009630       T0:0 T1:4\n",
       "6  3890082  T0:0 T1:5 T8:0\n",
       "7  1010073       T0:0 T1:6\n",
       "8  3348867       T0:0 T1:7\n",
       "9  4017062       T0:0 T1:8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T0:0', 'T1:0']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_attr(node):\n",
    "    attr = train[train.node_id == node].attributes.values\n",
    "    attr_lst = attr[0].split(' ')\n",
    "    return attr_lst  # format: TBD\n",
    "\n",
    "get_attr(5509623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T0:0', 'T1:1766']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test_node in test_nodes:\n",
    "def get_neighbor_lst(G,node):\n",
    "    neighbor_lst = [neighbor for neighbor in G.neighbors(node)]\n",
    "    return neighbor_lst\n",
    "\n",
    "\n",
    "def get_attr_from_neighbor(node): # test_node\n",
    "   \n",
    "    neighbor_lst = get_neighbor_lst(G,node)\n",
    "    attr_lst = []\n",
    "    for neighbor in neighbor_lst:\n",
    "        attr = get_attr(neighbor) # get neighbors' attributes\n",
    "        attr_lst += attr\n",
    "\n",
    "    return attr_lst\n",
    "    \n",
    "get_attr_from_neighbor(4546232)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T0:0', 'T1:1766']\n",
      "['T0:0', 'T1:1762', 'T0:0', 'T1:297', 'T0:0', 'T1:295']\n",
      "['T0:0', 'T1:1914', 'T8:0']\n"
     ]
    }
   ],
   "source": [
    "for test_node in test_nodes[:3]:\n",
    "    results = get_attr_from_neighbor(test_node)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I specify the attributes of a target node as adoption from its surrounding nodes. If the attribute type from its neighbors are unique, then the target node would adopt that attribute with value from its neighbor; if the attribute type is not unique, then I would evaluate based on the majority of its values, to decide the specific value for that type of attribute in our target node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T0:0', 'T1:1914', 'T8:0']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_format_result(test_node):\n",
    "    results = get_attr_from_neighbor(test_node)\n",
    "\n",
    "    dct = {}\n",
    "    typ_lst = []\n",
    "    val_lst = []\n",
    "\n",
    "    for attr in results:\n",
    "        typ_lst.append(attr.split(':')[0])\n",
    "        val_lst.append(attr.split(':')[1])\n",
    "\n",
    "    dct['attr_type'] = typ_lst\n",
    "    dct['value'] = val_lst\n",
    "\n",
    "    # parse into df\n",
    "    df = pd.DataFrame(dct)\n",
    "    df = df.drop_duplicates()\n",
    "    target_df = df.groupby('attr_type').agg(lambda x:x.value_counts().index[0])\n",
    "    target_df\n",
    "\n",
    "    # format\n",
    "    lst = []\n",
    "    for (t,v) in target_df.itertuples():\n",
    "        output_str = t + ':' + v\n",
    "        lst.append(output_str)\n",
    "\n",
    "    return lst\n",
    "\n",
    "get_format_result(test_nodes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time() \n",
    "attr_predictions = []\n",
    "for test_node in test_nodes[:132535]:\n",
    "    results = get_format_result(test_node)\n",
    "    attr_predictions.append(results)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"predictions created. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['id'] = test_nodes\n",
    "data['attr'] = attr_predictions # todo\n",
    "\n",
    "result_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the test dataset is quite huge, my computer simply would run forever when I implement the prediction all at at once. So I divide the test set into 5 batches, and predict each of them using the functions defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4546232"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide test data into 5 batches and predict each of them\n",
    "# test_nodes[:132535][0]  # -> 4546232   \n",
    "# test_nodes[132535:265070][0]  # -> 647698   \n",
    "# test_nodes[265070:397605][0]  # -> 3529436   \n",
    "# test_nodes[397605:530140] [0]  #  -> 90666   \n",
    "# test_nodes[530140:][0]   # -> 971066  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_bag5 created. Process took 1057.9442 seconds\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "start_time = time.time() \n",
    "predict_attrs_bag5 = []\n",
    "\n",
    "for test_node in test_nodes[530140:]:\n",
    "    predict_attrs_bag5.append(predict_node_attr(test_node))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"predictions_bag5 created. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "    \n",
    "# with open('task2_outputfile(bag5)', 'w') as fout:\n",
    "#     json.dump(predict_attrs_bag5, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, output the predictions to file. Once I get all the batches of predictions, I combined all of them locally by copying and pasting in a txt file, and clean it and reformat it as required in the instruction in another ipython script(see \"formatting.ipython\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
